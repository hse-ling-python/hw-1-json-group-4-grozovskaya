{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 1: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–≤–∏—Ç–æ–≤\n",
    "\n",
    "–î–µ–¥–ª–∞–π–Ω: 03.10.2019\n",
    "\n",
    "## –ó–∞–¥–∞–Ω–∏–µ 1\n",
    "\n",
    "–°–∫–æ–ª—å–∫–æ —Ç–≤–∏—Ç–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ?\n",
    "\n",
    "_**–†–µ—à–µ–Ω–∏–µ 1:**_\n",
    "\n",
    "(–ö–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç—É—Ç –Ω–µ—á–µ–≥–æ: —Ä–µ—à–µ–Ω–∏–µ –±—ã–ª–æ –¥–∞–Ω–æ –≤ –∫–æ–Ω–µ—Å–ø–µ–∫—Ç–µ —Å–µ–º–∏–Ω–∞—Ä–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2556\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "twits = []\n",
    "for line in open('hw_3_twitter.json'):\n",
    "    twits.append(json.loads(line))\n",
    "print(len(twits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "\n",
    "–ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ç–≤–∏—Ç–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç —É–¥–∞–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏? (–ø–æ–º–µ—á–µ–Ω–Ω—ã–µ –∫–∞–∫ deleted).\n",
    "\n",
    "_**–†–µ—à–µ–Ω–∏–µ 2:**_\n",
    "\n",
    "–ß–µ—Ä–µ–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é Twitter –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä Notepad —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ –µ—â—ë —Ä–∞–∑.\n",
    "\n",
    "–í –º–∞—Å—Å–∏–≤–µ twits –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å. \n",
    "\n",
    "–ò–∑ –≤—Å–µ—Ö –ø–∞—Ä –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è (–ø–æ—Ç–æ–º—É —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –ø–∞—Ä–µ —Å–∞–º–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—ë–º) –Ω–∞–º –Ω—É–∂–Ω—ã —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –∫–ª—é—á–∏ \"delete\".\n",
    "\n",
    "–ú–µ—Ç–æ–¥ get() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∫–ª—é—á—É. –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª—é—á–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –º–µ—Ç–æ–¥ –≤–µ—Ä–Ω—ë—Ç None –∏ –Ω–µ–Ω—É–∂–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø–æ–ø–∞–¥—ë—Ç –≤ –Ω–∞—à —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.16 %\n"
     ]
    }
   ],
   "source": [
    "deleted_twits = [] #—É–¥–∞–ª—ë–Ω–Ω—ã–µ —Ç–≤–∏—Ç—ã\n",
    "exist_twits = [] # –∑–∞–¥–µ–ª –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ 3: –Ω–µ-—É–¥–∞–ª—ë–Ω–Ω—ã–µ —Ç–≤–∏—Ç—ã\n",
    "\n",
    "for line in twits:\n",
    "    if line.get(\"delete\") != None: \n",
    "        deleted_twits.append(line)\n",
    "    else:\n",
    "        exist_twits.append(line)  # –∑–∞–¥–µ–ª –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ 3\n",
    "\n",
    "percentage = (len(deleted_twits)/len(twits))*100\n",
    "percentage = str(round(percentage, 2)) # –∑–∞–ø–∏—Å—å —Å 2–º—è –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–π\n",
    "print(percentage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 3\n",
    "\n",
    "–ö–∞–∫–∏–µ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —è–∑—ã–∫–∏ —Ç–≤–∏—Ç–æ–≤?\n",
    "\n",
    "_**–†–µ—à–µ–Ω–∏–µ 3:**_\n",
    "\n",
    "–í –ø—Ä–æ—à–ª–æ–º –∑–∞–¥–∞–Ω–∏–∏ –º—ã —Å–æ–∑–¥–∞–ª–∏ —Å–ø–∏—Å–æ–∫ –Ω–µ-—É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤ exist_twits. –¢–µ–ø–µ—Ä—å –±—É–¥–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ! –í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, —Å–µ–π—á–∞—Å.\n",
    "\n",
    "–ò–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –≤ —Å–ª–æ–≤–∞—Ä–µ-—Ç–≤–∏—Ç–µ –µ—Å—Ç—å –∫–ª—é—á \"user\". –ó–Ω–∞—á–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –∫–ª—é—á–∞ - —Å–ª–æ–≤–∞—Ä—å. –í –Ω—ë–º –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∞—è –Ω–∞—Å –ø–∞—Ä–∞ —Å –∫–ª—é—á–æ–º \"lang\" –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤ –≤–∏–¥–µ —Å–æ–∫—Ä–∞—â—ë–Ω–Ω–æ–≥–æ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è —è–∑—ã–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048   en\n",
      "411   ja\n",
      "183   es\n",
      "116   ko\n",
      "104   th\n",
      "80   pt\n",
      "69   ar\n",
      "39   fr\n",
      "27   id\n",
      "24   tr\n",
      "22   ru\n",
      "9   en-gb\n",
      "8   de\n",
      "8   it\n",
      "7   nl\n"
     ]
    }
   ],
   "source": [
    "lang_data = [] # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —è–∑—ã–∫–∞—Ö\n",
    "\n",
    "for line in exist_twits:\n",
    "    user_dict = line[\"user\"]\n",
    "    lang_data.append(user_dict.get(\"lang\"))\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(lang_data)\n",
    "lang_list = cntr.most_common(15)\n",
    "\n",
    "for item in lang_list: # –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "    print(item[1],\" \", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 4\n",
    "\n",
    "–ï—Å—Ç—å –ª–∏ —Ç–≤–∏—Ç—ã –æ—Ç –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è? –ï—Å–ª–∏ –¥–∞, —Ç–æ —Å–∫–æ–ª—å–∫–æ —Ç–∞–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π?\n",
    "\n",
    "**_–†–µ—à–µ–Ω–∏–µ 4:_**\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –∏–º–µ–Ω–∞ –º–æ–≥—É—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è, –∞ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—É–¥–æ–±–Ω–æ –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è, —Å–æ–∑–¥–∞—ë–º –∏—Ö –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫. –î–∞–ª—å—à–µ - —Å–æ—Å—Ç–∞–≤–ª—è–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —ç—Ç–∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π. –≠–ª–µ–º–µ–Ω—Ç—ã —á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å–ª–æ–≤–∏—é: –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫ –Ω–∞–ø–∏—Å–∞–ª –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ç–≤–∏—Ç–∞, —Ç–æ –º—ã –¥–æ–±–∞–≤–ª—è–µ–º 1 –≤ —Å—á—ë—Ç—á–∏–∫ \"num\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "id_name_data = [] # –≤—Å—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É—é—â–∞—è –∏–Ω—Ñ–∞\n",
    "\n",
    "for line in exist_twits:\n",
    "    user_dict = line[\"user\"]\n",
    "    id_ = user_dict.get(\"id_str\") # –¥–æ—Å—Ç–∞—ë–º ID\n",
    "    name = user_dict.get(\"name\") # –¥–æ—Å—Ç–∞—ë–º –∏–º—è\n",
    "    id_name = id_, name # –û–ü! ID-–∏–º—è –°:\n",
    "    id_name_data.append(id_name)\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(id_name_data)\n",
    "name_list = cntr.most_common() # —Å–ø–∏—Å–æ–∫ –∞–≤—Ç–æ—Ä–æ–≤, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –∫–æ–ª-–≤—É –∏—Ö —Ç–≤–∏—Ç–æ–≤\n",
    "\n",
    "num = 0 \n",
    "for item in name_list:\n",
    "    if item[1] > 1:\n",
    "        num = num + 1 # –∫–æ–ª-–≤–æ –∞–≤—Ç–æ—Ä–æ–≤, –Ω–∞–ø–∏—Å–∞–≤—à–∏—Ö –±–æ–ª–µ–µ 1–≥–æ —Ç–≤–∏—Ç–∞\n",
    "    \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 5\n",
    "\n",
    "–¢–æ–ø-20 —Ö—ç—à—Ç–µ–≥–æ–≤ (–¥–ª—è –Ω–∏—Ö –µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø–æ–ª–µ).\n",
    "\n",
    "_**–†–µ—à–µ–Ω–∏–µ 5:**_\n",
    "\n",
    "–ê–ª–≥–æ—Ä–∏—Ç–º –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂ –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ 3–≥–æ –∑–∞–¥–∞–Ω–∏—è, –Ω–æ –∑–¥–µ—Å—å –≤–Ω–æ–≤—å –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ñ–∞–π–ª–∞. –í—ã—è—Å–Ω–∏–ª–æ—Å—å, —á—Ç–æ –∫–ª—é—á \"hashtags\" —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ –Ω–µ —Å–ø–∏—Å–æ–∫, –∞ —Å–ª–æ–≤–∞—Ä—å, –∏ –µ–≥–æ –Ω—É–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å —Å –ø–æ–º–æ—â—å—é –∫–ª—é—á–∞ \"text\", —á—Ç–æ–±—ã –≤—ã—á–ª–µ–Ω–∏—Ç—å –Ω–∞–∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç —Ö—ç—à—Ç—ç–≥–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17   BTS\n",
      "13   Î∞©ÌÉÑÏÜåÎÖÑÎã®\n",
      "11   AMAs\n",
      "8   ‰∫∫Ê∞óÊäïÁ•®„Ç¨„ÉÅ„É£\n",
      "7   ÌÉúÌòï\n",
      "6   Î∑î\n",
      "5   BTSinChicago\n",
      "5   BTSLoveYourselfTour\n",
      "5   Ïò§ÎäòÏùòÎ∞©ÌÉÑ\n",
      "5   PledgeForSwachhBharat\n",
      "5   MPN\n",
      "4   PCAs\n",
      "4   V\n",
      "4   ÏãúÏπ¥Í≥†1ÌöåÏ∞®Í≥µÏó∞\n",
      "4   ‡πÄ‡∏õ‡πä‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡πÇ‡∏ä‡∏Ñ\n",
      "4   JIMIN\n",
      "3   running\n",
      "3   NCT\n",
      "3   ÏßÄÎØº\n",
      "3   WajahmuPlastik\n"
     ]
    }
   ],
   "source": [
    "hashtag_data = [] # –≤—Å–µ —Ö—ç—à—Ç—ç–≥–∏\n",
    "\n",
    "\n",
    "\n",
    "for line in exist_twits:\n",
    "    user_dict = line[\"entities\"] # –¥—Ä—É–≥–æ–π –∫–ª—é—á –¥–ª—è —Å–ª–æ–≤–∞—Ä—è-—Ç–≤–∏—Ç–∞\n",
    "    hashtag = user_dict.get(\"hashtags\") # –µ—â—ë –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å\n",
    "    \n",
    "    for item in hashtag:\n",
    "        #print(item)\n",
    "        hashtag_data.append(item.get(\"text\"))\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(hashtag_data)\n",
    "hashtag_list = cntr.most_common(20)\n",
    "\n",
    "for item in hashtag_list: # –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "    print(item[1],\" \", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 6\n",
    "\n",
    "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤ (–Ω–µ —Ä–µ—Ç–≤–∏—Ç–æ–≤) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ (—É–±—Ä–∞—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É) –∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å.\n",
    "\n",
    "**_–†–µ—à–µ–Ω–∏–µ 6:_**\n",
    "\n",
    "–î–ª—è –Ω–∞—á–∞–ª–∞ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–≤–∏—Ç—ã –æ—Ç —Ä–µ—Ç–≤–∏—Ç–æ–≤. –î–∞–ª–µ–µ - –≤—ã–±–∏—Ä–∞–µ–º –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ. –ó–∞—Ç–µ–º –≤—ã—á–ª–µ–Ω–∏–º –∏–∑ –Ω–∏—Ö —Ç–µ–∫—Å—Ç, —É—Ä–æ–≤–Ω—è–µ–º –∏ –ø–æ—á–∏—Å—Ç–∏–º –µ–≥–æ, –≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ - —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66   the\n",
      "37   and\n",
      "31   i\n",
      "30   to\n",
      "30   a\n",
      "24   you\n",
      "19   it\n",
      "19   is\n",
      "18   of\n",
      "16   in\n",
      "15   be\n",
      "14   on\n",
      "12   for\n",
      "12   not\n",
      "12   with\n",
      "11   that\n",
      "11   my\n",
      "10   so\n",
      "10   are\n",
      "10   have\n"
     ]
    }
   ],
   "source": [
    "original_twits = []\n",
    "for line in exist_twits: # –Ω–∞—Ö–æ–¥–∏–º –≤—Å–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–≤–∏—Ç—ã (–Ω–µ-—Ä–µ—Ç–≤–∏—Ç—ã)\n",
    "    if line.get(\"retweeted_status\") == None:\n",
    "        original_twits.append(line)\n",
    "\n",
    "en_twits = []    \n",
    "for line in original_twits: # –Ω–∞—Ö–æ–¥–∏–º —Å—Ä–µ–¥–∏ –Ω–∏—Ö –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ\n",
    "    user_dict = line[\"user\"]\n",
    "    if user_dict.get(\"lang\") == \"en\":\n",
    "        en_twits.append(line) # –ø–æ–ª—É—á–∞–µ–º –º–∞—Å—Å–∏–≤ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "        \n",
    "import re\n",
    "\n",
    "words = []\n",
    "for line in en_twits: # –ø—Ä–∏–≤–æ–¥–∏–º –∫–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    text = line.get(\"text\")\n",
    "    low_text = text.lower()\n",
    "    \n",
    "    word_list = re.findall(\" ([a-z]+) \", low_text) # –¥–æ—Å—Ç–∞—ë–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞\n",
    "    words.extend(word_list)\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(words)\n",
    "words_cntr = cntr.most_common(20)\n",
    "\n",
    "for item in words_cntr: # –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "    print(item[1],\" \", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 7\n",
    "\n",
    "–ù–∞–π—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ (—Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤) —É –∞–≤—Ç–æ—Ä–æ–≤ —Ç–≤–∏—Ç–æ–≤ –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø-10.\n",
    "\n",
    "**_–†–µ—à–µ–Ω–∏–µ 7:_**\n",
    "\n",
    "–ó–∞–¥–∞–Ω–∏–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ 4, –Ω–æ —Ç–µ–ø–µ—Ä—å –Ω–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–∏ \"–∏–º—è\" : \"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤\", —á—Ç–æ–±—ã –ø–æ—Ç–æ–º —Ä–∞—Å—Å—Ç–∞–≤–∏—Ç—å –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521403   Filosof√≠a‚ôï\n",
      "1491309   FITNESS Magazine\n",
      "1206759   malaysiakini.com\n",
      "1137374   NYT Science\n",
      "625463   Gram√°tica\n",
      "392472   TGRT Haber\n",
      "383698   The Sun Football ‚öΩ\n",
      "374222   Melbourne, Australia\n",
      "318189   Roznama Express\n",
      "311319   üíû ·É™≈≥‡Ωû…†…õ‡Ωû·É™∆°∆°…†ƒ±…õ üíû\n"
     ]
    }
   ],
   "source": [
    "name_fcount_data = {} # —Å–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "for line in exist_twits:\n",
    "    user_dict = line[\"user\"]\n",
    "    name = user_dict.get(\"name\")  \n",
    "    fcount = user_dict.get(\"followers_count\") \n",
    "    name_fcount_data[name] = [fcount] # —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä—ã –∏–º—è:–∫–æ–ª-–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(name_fcount_data)\n",
    "popular_list = cntr.most_common(10)\n",
    "\n",
    "for item in popular_list: # –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "    print(item[1][0],\" \", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 8*\n",
    "\n",
    "–¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–≤–∏—Ç–∞ (–∏–∑ –∫–∞–∫–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞–ø–∏—Å–∞–Ω) (–ø–æ–¥—Å–∫–∞–∑–∫–∞: –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è).\n",
    "\n",
    "_**–†–µ—à–µ–Ω–∏–µ 8:**_\n",
    "\n",
    "–°–º–æ—Ç—Ä–∏–º –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¢–≤–∏—Ç—Ç–µ—Ä–∞, –ø–æ—Ç–æ–º —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–æ, –∫–∞–∫ –≤—Å—ë —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –≤ –Ω–∞—Å—Ç–æ—è—â–µ–º —Ñ–∞–π–ª–µ. –ù–∞—Ö–æ–¥–∏–º –∫–∞–∫–∏–µ-—Ç–æ –æ–ø–æ—Ä–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, rel=\"nofollow\">) –∏ –≤ —Å–≤–æ—ë–º —Ä–µ–≥—É–ª—è—Ä–Ω–æ–º –≤—ã—Ä–∞–∂–µ–Ω–∏–∏ –æ—Ç—Ä–∞–∂–∞–µ–º –∏—Ö, –∞ —Ç–æ—Ç –∫—É—Å–æ—á–µ–∫ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Å –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, –≤—ã–¥–µ–ª—è–µ–º –∫—Ä—É–≥–ª—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏.\n",
    "–ü—Ä–∏–≤—ã—á–Ω–æ —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å—ë –≤ —Å–ø–∏—Å–æ—á–µ–∫ –∏ –¥–µ–ª–∞–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800   Twitter for iPhone\n",
      "695   Twitter for Android\n",
      "140   Twitter Web Client\n",
      "122   twittbot.net\n",
      "51   Twitter Lite\n",
      "28   Twitter for iPad\n",
      "23   TweetDeck\n",
      "17   Facebook\n",
      "14   IFTTT\n",
      "10   ÿ™ÿ∑ÿ®ŸäŸÇ ŸÇÿ±ÿ¢ŸÜŸä\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "source_list = []\n",
    "for line in exist_twits:\n",
    "    source_item = line.get(\"source\")\n",
    "    result = re.findall('rel=\"nofollow\">(.+)</a>', source_item)\n",
    "    source_list.extend(result)\n",
    "\n",
    "from collections import Counter # —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "cntr = Counter(source_list)\n",
    "sources = cntr.most_common(10)\n",
    "\n",
    "for item in sources: # –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "    print(item[1],\" \", item[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
